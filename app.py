import os
import sys

os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"

# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # æœªå®‰è£… dotenvï¼Œè·³è¿‡

if "--device" in sys.argv:
    try:
        device_idx = sys.argv.index("--device")
        device_value = sys.argv[device_idx + 1]
        os.environ["DOCLING_DEVICE"] = device_value
        print(f"[INFO] DOCLING_DEVICE å·²è®¾ç½®ä¸º: {device_value}")
    except (IndexError, ValueError):
        print("[WARNING] --device éœ€è¦ä¸€ä¸ªå€¼ï¼ˆcpu æˆ– cudaï¼‰")

os.environ["GRADIO_LANGUAGE"] = "zh-CN"

import uuid
import time
import shutil
import threading
import json
from typing import Optional, Tuple, List, Dict, Any

import gradio as gr
from fastapi import FastAPI

def _noop(self, app: FastAPI):
    pass

gr.blocks.Blocks._add_health_routes = _noop

from rebuttal_service import (
    rebuttal_service,
    ProcessStatus,
    SessionState,
    QuestionState,
    init_llm_client,
    LogCollector,
)
from paper_reading_service import paper_reading_service


_CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SAVE_DIR = os.path.join(_CURRENT_DIR, "gradio_uploads")
os.makedirs(SAVE_DIR, exist_ok=True)

def read_gradio_file(file_obj) -> Tuple[Optional[str], Optional[Any]]:
    if file_obj is None:
        return None, None

    if isinstance(file_obj, str):
        return "path", file_obj
    if isinstance(file_obj, dict) and "data" in file_obj:
        return "bytes", file_obj["data"]
    if hasattr(file_obj, "read"):
        return "fileobj", file_obj.read()

    raise ValueError(f"æœªçŸ¥çš„ gr.File å¯¹è±¡æ ¼å¼: {type(file_obj)}")


def save_uploaded_files(pdf_file, review_file, session_id: str) -> Tuple[str, str, str]:
    session_dir = os.path.join(SAVE_DIR, session_id)
    os.makedirs(session_dir, exist_ok=True)
    
    pdf_save_path = os.path.join(session_dir, "paper.pdf")
    review_save_path = os.path.join(session_dir, "review.txt")
    
    pdf_type, pdf_data = read_gradio_file(pdf_file)
    if pdf_type is None:
        raise ValueError("PDF æ–‡ä»¶ä¸Šä¼ å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®")
    if pdf_type == "path":
        shutil.copy(pdf_data, pdf_save_path)
    elif pdf_type in ("bytes", "fileobj"):
        with open(pdf_save_path, "wb") as f:
            f.write(pdf_data if isinstance(pdf_data, bytes) else pdf_data)
    
    rev_type, rev_data = read_gradio_file(review_file)
    if rev_type is None:
        raise ValueError("è¯„å®¡æ–‡ä»¶ä¸Šä¼ å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®")
    review_text = ""
    

    def decode_with_fallback(data: bytes) -> str:
        """å°è¯•å¤šç§ç¼–ç è§£ç å­—èŠ‚ï¼Œä¼˜å…ˆä½¿ç”¨ UTF-8ã€‚"""
        encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
        for enc in encodings:
            try:
                return data.decode(enc)
            except (UnicodeDecodeError, LookupError):
                continue

        return data.decode('utf-8', errors='replace')
    
    if rev_type == "path":
        with open(rev_data, "rb") as f:
            raw_bytes = f.read()
        review_text = decode_with_fallback(raw_bytes)
    elif rev_type in ("bytes", "fileobj"):
        if isinstance(rev_data, bytes):
            review_text = decode_with_fallback(rev_data)
        else:
            review_text = decode_with_fallback(rev_data)
    
    with open(review_save_path, "w", encoding="utf-8") as f:
        f.write(review_text)
    
    return pdf_save_path, review_save_path, review_text


def save_paper_reading_files(pdf_file, research_field_file, session_id: str) -> Tuple[str, str]:
    """ä¿å­˜è®ºæ–‡é˜…è¯»æµç¨‹çš„ä¸Šä¼ æ–‡ä»¶"""
    session_dir = os.path.join(SAVE_DIR, session_id)
    os.makedirs(session_dir, exist_ok=True)
    
    pdf_save_path = os.path.join(session_dir, "paper.pdf")
    research_field_save_path = os.path.join(session_dir, "research_field.md")
    
    pdf_type, pdf_data = read_gradio_file(pdf_file)
    if pdf_type is None:
        raise ValueError("PDF æ–‡ä»¶ä¸Šä¼ å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®")
    if pdf_type == "path":
        shutil.copy(pdf_data, pdf_save_path)
    elif pdf_type in ("bytes", "fileobj"):
        with open(pdf_save_path, "wb") as f:
            f.write(pdf_data if isinstance(pdf_data, bytes) else pdf_data)
    
    rf_type, rf_data = read_gradio_file(research_field_file)
    if rf_type is None:
        raise ValueError("ç ”ç©¶é¢†åŸŸæ–‡ä»¶ä¸Šä¼ å¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®")
    
    def decode_with_fallback(data: bytes) -> str:
        """å°è¯•å¤šç§ç¼–ç è§£ç å­—èŠ‚ï¼Œä¼˜å…ˆä½¿ç”¨ UTF-8ã€‚"""
        encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
        for enc in encodings:
            try:
                return data.decode(enc)
            except (UnicodeDecodeError, LookupError):
                continue
        return data.decode('utf-8', errors='replace')
    
    research_field_text = ""
    if rf_type == "path":
        with open(rf_data, "rb") as f:
            raw_bytes = f.read()
        research_field_text = decode_with_fallback(raw_bytes)
    elif rf_type in ("bytes", "fileobj"):
        if isinstance(rf_data, bytes):
            research_field_text = decode_with_fallback(rf_data)
        else:
            research_field_text = decode_with_fallback(rf_data)
    
    with open(research_field_save_path, "w", encoding="utf-8") as f:
        f.write(research_field_text)
    
    return pdf_save_path, research_field_save_path


processing_threads: Dict[str, threading.Thread] = {}

# ä¾›åº”å•†é…ç½®
PROVIDER_CONFIGS = {
    "OpenRouter": {
        "provider_key": "openrouter",
        "env_var": "OPENROUTER_API_KEY",
        "label": "OpenRouter API å¯†é’¥",
        "placeholder": "sk-or-v1-...",
    },
    "Qwen (DashScope)": {
        "provider_key": "qwen",
        "env_var": "QWEN_API_KEY",
        "label": "Qwen API å¯†é’¥",
        "placeholder": "sk-...",
    },
    "DeepSeek": {
        "provider_key": "deepseek",
        "env_var": "DEEPSEEK_API_KEY",
        "label": "DeepSeek API å¯†é’¥",
        "placeholder": "sk-...",
    },
    "OpenAI": {
        "provider_key": "openai",
        "env_var": "OPENAI_API_KEY",
        "label": "OpenAI API å¯†é’¥",
        "placeholder": "sk-...",
    },
    "Gemini": {
        "provider_key": "gemini",
        "env_var": "GEMINI_API_KEY",
        "label": "Gemini API å¯†é’¥",
        "placeholder": "AIza...",
    },
    "ZhiPu (GLM)": {
        "provider_key": "zhipu",
        "env_var": "ZHIPUAI_API_KEY",
        "label": "æ™ºè°± API å¯†é’¥",
        "placeholder": "...",
    },
}

# å„ä¾›åº”å•†æ¨¡å‹é€‰é¡¹
MODEL_CHOICES_BY_PROVIDER = {
    "OpenRouter": {
        "Gemini 3 Flash": "google/gemini-3-flash-preview",
        "Grok 4.1 Fast": "x-ai/grok-4.1-fast",
        "GPT-5 Mini": "openai/gpt-5-mini",
        "DeepSeek V3.2": "deepseek/deepseek-chat-v3.2",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
    "Qwen (DashScope)": {
        "Qwen-Turbo": "qwen-turbo",
        "Qwen-Plus": "qwen-plus",
        "Qwen-Max": "qwen-max",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
    "DeepSeek": {
        "DeepSeek Chat": "deepseek-chat",
        "DeepSeek Reasoner": "deepseek-reasoner",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
    "OpenAI": {
        "GPT-5.2": "gpt-5.2",
        "GPT-5 Mini": "gpt-5-mini",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
    "Gemini": {
        "Gemini-3-Pro": "gemini-3-pro-preview",
        "Gemini-3-Flash": "models/gemini-3-flash-preview",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
    "ZhiPu (GLM)": {
        "GLM-4.7": "glm-4.7",
        "å…¶ä»–æ¨¡å‹": "custom",
    },
}




def get_api_key_for_provider(provider: str) -> str:
    """ä»ç¯å¢ƒå˜é‡è·å–æŒ‡å®šä¾›åº”å•†çš„ API å¯†é’¥"""
    config = PROVIDER_CONFIGS.get(provider, PROVIDER_CONFIGS["OpenRouter"])
    return os.environ.get(config["env_var"], "")


def get_default_model_for_provider(provider: str) -> str:
    """è·å–æŒ‡å®šä¾›åº”å•†çš„é»˜è®¤æ¨¡å‹"""
    models = MODEL_CHOICES_BY_PROVIDER.get(provider, MODEL_CHOICES_BY_PROVIDER["OpenRouter"])
    # è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼ˆæ’é™¤â€œå…¶ä»–æ¨¡å‹â€ï¼‰
    for name, value in models.items():
        if name != "å…¶ä»–æ¨¡å‹":
            return name
    return list(models.keys())[0]


def start_analysis(pdf_file, review_file, provider_choice, api_key, model_choice, custom_model):
    if not pdf_file or not review_file:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            "âš ï¸ è¯·ä¸Šä¼ è®ºæ–‡ PDF å’Œè¯„å®¡æ–‡ä»¶ï¼",
            gr.Timer(active=False),  
        )
    
    if not api_key or not api_key.strip():
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            "âš ï¸ è¯·è¾“å…¥ API å¯†é’¥ï¼",
            gr.Timer(active=False),
        )
    
    # ä»é…ç½®è·å–ä¾›åº”å•† key
    provider_config = PROVIDER_CONFIGS.get(provider_choice, PROVIDER_CONFIGS["OpenRouter"])
    provider_key = provider_config["provider_key"]
    
    # è·å–è¯¥ä¾›åº”å•†çš„æ¨¡å‹é€‰é¡¹
    model_choices = MODEL_CHOICES_BY_PROVIDER.get(provider_choice, MODEL_CHOICES_BY_PROVIDER["OpenRouter"])
    
    if model_choice == "å…¶ä»–æ¨¡å‹":
        if not custom_model or not custom_model.strip():
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                None,
                "âš ï¸ è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°ï¼",
                gr.Timer(active=False),
            )
        selected_model = custom_model.strip()
    else:
        selected_model = model_choices.get(model_choice, list(model_choices.values())[0])
    
    session_id = str(uuid.uuid4())[:8]
    
    try:
        init_llm_client(api_key=api_key.strip(), provider=provider_key, model=selected_model)
        pdf_path, review_path, _ = save_uploaded_files(pdf_file, review_file, session_id)
        session = rebuttal_service.create_session(session_id, pdf_path, review_path)
        
        return (
            gr.update(visible=False),
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            {"session_id": session_id, "current_idx": 0},
            "ğŸ“¤ æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨åˆå§‹åŒ–åˆ†æ...",
            gr.Timer(active=True),  
        )
        
    except Exception as e:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}",
            gr.Timer(active=False),
        )


def run_initial_analysis(session_state):
    if not session_state:
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            gr.update(visible=False),
            session_state,
            "âŒ ä¼šè¯çŠ¶æ€ä¸¢å¤±",
            gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.Timer(active=False), 
        )
    
    session_id = session_state.get("session_id")
    
    try:
        session = rebuttal_service.run_initial_analysis(session_id)
        rebuttal_service.process_all_questions_parallel(session_id, max_workers=3)
        session = rebuttal_service.get_session(session_id)
        
        session_state["current_idx"] = 0
        q_state = session.questions[0]
        
        history_text = format_feedback_history(q_state.feedback_history)
        strategy_content = q_state.agent7_output or ""
        
        # æ ¹æ®æ˜¯å¦ä¸ºæœ€åä¸€ä¸ªé—®é¢˜å†³å®šæŒ‰é’®æ–‡æ¡ˆ
        is_last_question = len(session.questions) == 1
        btn_text = "ğŸ“ ç”Ÿæˆæœ€ç»ˆå›å¤" if is_last_question else "âœ… å·²æ»¡è¶³ï¼Œä¸‹ä¸€æ¡é—®é¢˜"
        
        return (
            gr.update(visible=False),
            gr.update(visible=False),
            gr.update(visible=True),
            gr.update(visible=False),
            session_state,
            "",
            f"### é—®é¢˜ 1 / {len(session.questions)}",
            q_state.question_text,
            strategy_content,
            strategy_content,
            "",
            f"ğŸ“ å·²ä¿®è®¢ {q_state.revision_count} æ¬¡",
            gr.update(interactive=True),
            history_text,
            gr.Timer(active=False),
            gr.update(value=btn_text),
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            gr.update(visible=False),
            session_state,
            f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}",
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.Timer(active=False),
            gr.update(),
        )


def regenerate_strategy(feedback_text, session_state):
    if not session_state:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            session_state,
        )
    
    if not feedback_text or not feedback_text.strip():
        return (
            gr.update(),
            gr.update(),
            "âš ï¸ è¯·è¾“å…¥åé¦ˆ",
            gr.update(),
            session_state,
        )
    
    session_id = session_state.get("session_id")
    current_idx = session_state.get("current_idx", 0)
    
    try:
        q_state = rebuttal_service.revise_with_feedback(
            session_id, 
            current_idx, 
            feedback_text.strip()
        )
        
        history_text = format_feedback_history(q_state.feedback_history)
        strategy_content = q_state.agent7_output or ""
        
        return (
            strategy_content,
            strategy_content,
            "",
            f"ğŸ“ å·²ä¿®è®¢ {q_state.revision_count} æ¬¡ âœ“ å·²åº”ç”¨æœ€æ–°ä¿®è®¢",
            history_text,
            session_state,
        )
        
    except Exception as e:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            f"âŒ ä¿®è®¢å¤±è´¥ï¼š{str(e)}",
            gr.update(),
            session_state,
        )


def format_feedback_history(history: list) -> str:
    if not history:
        return "*å°šæ— ä¿®è®¢*"
    
    lines = []
    for i, record in enumerate(history, 1):
        feedback = record.get("feedback", "")
        if len(feedback) > 100:
            feedback = feedback[:100] + "..."
        lines.append(f"**#{i}** {feedback}")
    
    return "\n\n".join(lines)


def generate_strategy_summary(session) -> str:
    lines = []
    lines.append(" æœ¬æ–‡æ¡£åŒ…å«æ‰€æœ‰é—®é¢˜çš„å›å¤ç­–ç•¥ä¸å¾…åŠæ¸…å•\n")
    lines.append("=" * 60 + "\n")
    
    for q in session.questions:
        lines.append(f"## é—®é¢˜{q.question_id}: {q.question_text[:100]}{'...' if len(q.question_text) > 100 else ''}")
        lines.append("")
        lines.append("### å›å¤ç­–ç•¥ä¸å¾…åŠæ¸…å•")
        lines.append("")
        lines.append(q.agent7_output if q.agent7_output else "**å°šæœªç”Ÿæˆ**")
        lines.append("")
        if q.revision_count > 0:
            lines.append(f"> ğŸ“ å·²ä¿®è®¢ {q.revision_count} æ¬¡")
        lines.append("")
        lines.append("-" * 40)
        lines.append("")
    
    return "\n".join(lines)


def skip_question(session_state):
    if not session_state:
        return (
            gr.update(),
            gr.update(),
            session_state,
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(),
        )
    
    session_id = session_state.get("session_id")
    current_idx = session_state.get("current_idx", 0)
    
    try:
        session = rebuttal_service.get_session(session_id)
        
        if not session:
            raise ValueError(f"æœªæ‰¾åˆ°ä¼šè¯ {session_id}")
        
        rebuttal_service.mark_question_satisfied(session_id, current_idx)
        
        next_idx = current_idx + 1
        
        if next_idx < len(session.questions):
            q_state = session.questions[next_idx]
            session_state["current_idx"] = next_idx
            
            history_text = format_feedback_history(q_state.feedback_history)
            
            strategy_content = q_state.agent7_output or ""
            
            # æ ¹æ®æ˜¯å¦ä¸ºæœ€åä¸€ä¸ªé—®é¢˜å†³å®šæŒ‰é’®æ–‡æ¡ˆ
            is_last_question = (next_idx + 1) == len(session.questions)
            btn_text = "ğŸ“ ç”Ÿæˆæœ€ç»ˆå›å¤" if is_last_question else "âœ… å·²æ»¡è¶³ï¼Œä¸‹ä¸€æ¡é—®é¢˜"
            
            return (
                gr.update(visible=True),
                gr.update(visible=False),
                session_state,
                f"### é—®é¢˜ {next_idx + 1} / {len(session.questions)}",
                q_state.question_text,
                strategy_content,
                strategy_content,
                "",
                f"ğŸ“ å·²ä¿®è®¢ {q_state.revision_count} æ¬¡",
                gr.update(interactive=True),
                history_text,
                gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(value=btn_text),
            )
        else:
            strategy_summary = generate_strategy_summary(session)
            final_text = rebuttal_service.generate_final_rebuttal(session_id)
            
            return (
                gr.update(visible=False),
                gr.update(visible=True),
                session_state,
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(),
                strategy_summary, strategy_summary, final_text, final_text,
                gr.update(),
            )
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return (
            gr.update(),
            gr.update(),
            session_state,
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}",
            gr.update(),
        )


def confirm_and_next(strategy_text, session_state):
    if not session_state:
        return (
            gr.update(),
            gr.update(),
            session_state,
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(),
        )
    
    session_id = session_state.get("session_id")
    current_idx = session_state.get("current_idx", 0)
    
    try:
        session = rebuttal_service.get_session(session_id)
        
        if not session:
            raise ValueError(f"æœªæ‰¾åˆ°ä¼šè¯ {session_id}")
        
        session.questions[current_idx].agent7_output = strategy_text
        rebuttal_service.mark_question_satisfied(session_id, current_idx)
        
        next_idx = current_idx + 1
        
        if next_idx < len(session.questions):
            q_state = session.questions[next_idx]
            session_state["current_idx"] = next_idx
            
            history_text = format_feedback_history(q_state.feedback_history)
            
            strategy_content = q_state.agent7_output or ""
            
            # æ ¹æ®æ˜¯å¦ä¸ºæœ€åä¸€ä¸ªé—®é¢˜å†³å®šæŒ‰é’®æ–‡æ¡ˆ
            is_last_question = (next_idx + 1) == len(session.questions)
            btn_text = "ğŸ“ ç”Ÿæˆæœ€ç»ˆå›å¤" if is_last_question else "âœ… å·²æ»¡è¶³ï¼Œä¸‹ä¸€æ¡é—®é¢˜"
            
            return (
                gr.update(visible=True),
                gr.update(visible=False),
                session_state,
                f"### é—®é¢˜ {next_idx + 1} / {len(session.questions)}",
                q_state.question_text,
                strategy_content,
                strategy_content,
                "",
                f"ğŸ“ å·²ä¿®è®¢ {q_state.revision_count} æ¬¡",
                gr.update(interactive=True),
                history_text,
                gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(value=btn_text),
            )
        else:
            strategy_summary = generate_strategy_summary(session)
            final_text = rebuttal_service.generate_final_rebuttal(session_id)
            
            return (
                gr.update(visible=False),
                gr.update(visible=True),
                session_state,
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(),
                strategy_summary, strategy_summary, final_text, final_text,
                gr.update(),
            )
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return (
            gr.update(),
            gr.update(),
            session_state,
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}",
            gr.update(),
        )


def restart_session():
    return (
        gr.update(visible=True),
        gr.update(visible=False),
        gr.update(visible=False),
        gr.update(visible=False),
        None,
        "",
        None, None,
    )


def get_active_sessions_choices():
    """è·å–ä¼šè¯ä¸‹æ‹‰é€‰é¡¹"""
    sessions = rebuttal_service.list_active_sessions()
    if not sessions:
        return []
    return [(s["display_text"], s["session_id"]) for s in sessions]


def refresh_session_list():
    """åˆ·æ–°ä¼šè¯ä¸‹æ‹‰é€‰é¡¹"""
    choices = get_active_sessions_choices()
    if not choices:
        return gr.update(choices=[], value=None), "ğŸ“­ æœªå‘ç°æ´»åŠ¨ä¼šè¯"
    return gr.update(choices=choices, value=choices[0][1]), f"ğŸ”„ å‘ç° {len(choices)} ä¸ªæ´»åŠ¨ä¼šè¯"


def resume_session(session_id_to_resume, provider_choice, api_key):
    """é¡µé¢åˆ·æ–°åæ¢å¤å·²æœ‰ä¼šè¯"""
    if not session_id_to_resume:
        return (
            gr.update(),  # upload_col
            gr.update(),  # loading_col
            gr.update(),  # interact_col
            gr.update(),  # result_col
            None,         # session_state
            "âš ï¸ è¯·é€‰æ‹©è¦æ¢å¤çš„ä¼šè¯ï¼",  # upload_status
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(),  # confirm_btn
        )
    
    if not api_key or not api_key.strip():
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            "âš ï¸ æ¢å¤å‰è¯·è¾“å…¥ API å¯†é’¥ï¼",
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(),
        )
    
    try:
        # ä½¿ç”¨æä¾›çš„å‡­æ®åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        provider_config = PROVIDER_CONFIGS.get(provider_choice, PROVIDER_CONFIGS["OpenRouter"])
        provider_key = provider_config["provider_key"]
        model_choices = MODEL_CHOICES_BY_PROVIDER.get(provider_choice, MODEL_CHOICES_BY_PROVIDER["OpenRouter"])
        default_model = list(model_choices.values())[0]
        init_llm_client(api_key=api_key.strip(), provider=provider_key, model=default_model)
        
        session = rebuttal_service.get_session(session_id_to_resume)
        if not session:
            session = rebuttal_service.restore_session_from_disk(session_id_to_resume)
        if not session:
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                None,
                f"âŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id_to_resume}ï¼",
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(),
                gr.update(),
            )
        
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²æœ‰é—®é¢˜è¢«å¤„ç†
        if not session.questions:
            return (
                gr.update(),
                gr.update(visible=True),  # Show loading page
                gr.update(),
                gr.update(),
                {"session_id": session_id_to_resume, "current_idx": 0},
                "ğŸ“¤ å·²æ‰¾åˆ°ä¼šè¯ä½†ä»åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...",
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(),
                gr.update(),
            )
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªå¤„ç†æˆ–æœªæ»¡æ„çš„é—®é¢˜
        resume_idx = 0
        for i, q in enumerate(session.questions):
            if not q.is_satisfied and q.agent7_output:
                resume_idx = i
                break
            elif q.is_satisfied:
                resume_idx = i + 1
        
        # å¦‚æœå…¨éƒ¨é—®é¢˜å·²æ»¡è¶³ï¼Œè·³è½¬åˆ°ç»“æœé¡µ
        if resume_idx >= len(session.questions):
            strategy_summary = generate_strategy_summary(session)
            final_text = session.final_rebuttal or rebuttal_service.generate_final_rebuttal(session_id_to_resume)
            
            return (
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=True),  # æ˜¾ç¤ºç»“æœé¡µ
                {"session_id": session_id_to_resume, "current_idx": resume_idx - 1},
                "",
                gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
                gr.update(), gr.update(), gr.update(),
                gr.update(),
            )
        
        # æ¢å¤åˆ°é—®é¢˜å®¡é˜…é¡µé¢
        q_state = session.questions[resume_idx]
        history_text = format_feedback_history(q_state.feedback_history)
        strategy_content = q_state.agent7_output or ""
        
        is_last_question = (resume_idx + 1) == len(session.questions)
        btn_text = "ğŸ“ ç”Ÿæˆæœ€ç»ˆå›å¤" if is_last_question else "âœ… å·²æ»¡è¶³ï¼Œä¸‹ä¸€æ¡é—®é¢˜"
        
        return (
            gr.update(visible=False),  # upload_col
            gr.update(visible=False),  # loading_col
            gr.update(visible=True),   # interact_col
            gr.update(visible=False),  # result_col
            {"session_id": session_id_to_resume, "current_idx": resume_idx},  # session_state
            "",  # upload_status
            f"### é—®é¢˜ {resume_idx + 1} / {len(session.questions)}ï¼ˆå·²æ¢å¤ï¼‰",  # progress_info
            q_state.question_text,  # question_display
            strategy_content,  # strategy_preview
            strategy_content,  # strategy_edit
            "",  # feedback_input
            f"ğŸ“ å·²ä¿®è®¢ {q_state.revision_count} æ¬¡",  # revision_info
            gr.update(interactive=True),  # regenerate_btn
            history_text,  # feedback_history_display
            gr.update(value=btn_text),  # confirm_btn
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            f"âŒ æ¢å¤ä¼šè¯å¤±è´¥ï¼š{str(e)}",
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(),
            gr.update(),
        )


def poll_logs(session_state):
    """è½®è¯¢åŠ è½½é¡µçš„å®æ—¶æ—¥å¿—æ›´æ–°"""
    if not session_state:
        return gr.update(), session_state
    
    session_id = session_state.get("session_id")
    if not session_id:
        return gr.update(), session_state
    
    session = rebuttal_service.get_session(session_id)
    if not session or not session.log_collector:
        return gr.update(), session_state
    
    logs = session.log_collector.get_recent(30)
    if not logs:
        return gr.update(), session_state
    
    prev_logs = session_state.get("_prev_logs", "")
    if logs == prev_logs:
        return gr.update(), session_state
    
    session_state["_prev_logs"] = logs
    return logs, session_state


def poll_pr_logs(pr_session_state):
    """è½®è¯¢è®ºæ–‡é˜…è¯»æµç¨‹æ—¥å¿—"""
    if not pr_session_state:
        return gr.update(), pr_session_state
    
    session_id = pr_session_state.get("session_id")
    if not session_id:
        return gr.update(), pr_session_state
    
    session = paper_reading_service.get_session(session_id)
    if not session or not session.log_collector:
        return gr.update(), pr_session_state
    
    logs = session.log_collector.get_recent(30)
    if not logs:
        return gr.update(), pr_session_state
    
    prev_logs = pr_session_state.get("_prev_logs", "")
    if logs == prev_logs:
        return gr.update(), pr_session_state
    
    pr_session_state["_prev_logs"] = logs
    return logs, pr_session_state


def start_paper_reading(pdf_file, research_field_file, provider_choice, api_key, model_choice, custom_model):
    """å¯åŠ¨è®ºæ–‡é˜…è¯»æµç¨‹"""
    if not pdf_file or not research_field_file:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            "âš ï¸ è¯·ä¸Šä¼ è®ºæ–‡ PDF å’Œç ”ç©¶é¢†åŸŸæ–‡ä»¶ï¼",
            gr.Timer(active=False),
        )
    
    if not api_key or not api_key.strip():
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            "âš ï¸ è¯·è¾“å…¥ API å¯†é’¥ï¼",
            gr.Timer(active=False),
        )
    
    provider_config = PROVIDER_CONFIGS.get(provider_choice, PROVIDER_CONFIGS["OpenRouter"])
    provider_key = provider_config["provider_key"]
    
    model_choices = MODEL_CHOICES_BY_PROVIDER.get(provider_choice, MODEL_CHOICES_BY_PROVIDER["OpenRouter"])
    
    if model_choice == "å…¶ä»–æ¨¡å‹":
        if not custom_model or not custom_model.strip():
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                None,
                "âš ï¸ è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°ï¼",
                gr.Timer(active=False),
            )
        selected_model = custom_model.strip()
    else:
        selected_model = model_choices.get(model_choice, list(model_choices.values())[0])
    
    session_id = str(uuid.uuid4())[:8]
    
    try:
        init_llm_client(api_key=api_key.strip(), provider=provider_key, model=selected_model)
        pdf_path, research_field_path = save_paper_reading_files(pdf_file, research_field_file, session_id)
        session = paper_reading_service.create_session(session_id, pdf_path, research_field_path)
        
        pr_session_state = {
            "session_id": session_id,
            "current_innovation_idx": 0,
            "current_keyword_idx": 0,
            "current_agent3_idx": 0,
            "current_agent4_idx": 0,
            "agent2_data": None,
            "agent3_data": None,
            "agent4_data": None
        }
        
        return (
            gr.update(visible=False),
            gr.update(visible=True),
            gr.update(visible=False),
            pr_session_state,
            "ğŸ“¤ æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨åˆå§‹åŒ–åˆ†æ...",
            gr.Timer(active=True),
        )
        
    except Exception as e:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            None,
            f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}",
            gr.Timer(active=False),
        )


def run_paper_reading_workflow(pr_session_state):
    """æ‰§è¡Œè®ºæ–‡é˜…è¯»æµç¨‹å¹¶æ›´æ–°ç•Œé¢"""
    if not pr_session_state:
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            pr_session_state,
            "âŒ ä¼šè¯çŠ¶æ€ä¸¢å¤±",
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            gr.Timer(active=False),
        )
    
    session_id = pr_session_state.get("session_id")
    
    try:
        result = paper_reading_service.run_workflow(session_id)
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€æ•°æ®
        pr_session_state.update({
            "agent2_data": result["agent2"],
            "agent3_data": result["agent3"],
            "agent4_data": result["agent4"]
        })
        
        # æ ¼å¼åŒ–è¾“å‡º
        agent1_formatted = json.dumps(result["agent1"], indent=2, ensure_ascii=False)
        agent2_summary_text = result["agent2"].get("full_summary", "")
        innovations = result["agent2"].get("innovations", [])
        keywords = result["agent2"].get("keywords", [])
        agent2_innovation_text = innovations[0] if innovations else ""
        agent2_keyword_text = keywords[0] if keywords else ""
        agent3_text = result["agent3"][0] if result["agent3"] else ""
        agent4_text = result["agent4"][0] if result["agent4"] else ""
        agent5_formatted = json.dumps(result["agent5"], indent=2, ensure_ascii=False)
        
        return (
            gr.update(visible=False),
            gr.update(visible=False),
            gr.update(visible=True),
            pr_session_state,
            "",
            agent1_formatted,
            agent2_summary_text,
            agent2_innovation_text,
            f"åˆ›æ–°ç‚¹ 1/{len(innovations)}" if innovations else "åˆ›æ–°ç‚¹ 0/0",
            agent2_keyword_text,
            f"å…³é”®è¯ 1/{len(keywords)}" if keywords else "å…³é”®è¯ 0/0",
            agent3_text,
            f"åˆ›æ–°ç‚¹åˆ†æ 1/{len(result['agent3'])}" if result["agent3"] else "åˆ›æ–°ç‚¹åˆ†æ 0/0",
            agent4_text,
            f"åº”ç”¨ä»·å€¼åˆ†æ 1/{len(result['agent4'])}" if result["agent4"] else "åº”ç”¨ä»·å€¼åˆ†æ 0/0",
            agent5_formatted,
            gr.Timer(active=False),
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            pr_session_state,
            f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}",
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(), gr.update(),
            gr.update(), gr.update(), gr.update(), gr.update(),
            gr.Timer(active=False),
        )


def update_innovation_display(pr_session_state, direction):
    """æ›´æ–° Agent2 åˆ›æ–°ç‚¹å±•ç¤º"""
    if not pr_session_state:
        return pr_session_state, gr.update(), gr.update()
    
    current_idx = pr_session_state.get("current_innovation_idx", 0)
    innovations = pr_session_state.get("agent2_data", {}).get("innovations", [])
    
    if not innovations:
        return pr_session_state, gr.update(), gr.update()
    
    if direction == "next":
        current_idx = min(current_idx + 1, len(innovations) - 1)
    elif direction == "prev":
        current_idx = max(current_idx - 1, 0)
    
    pr_session_state["current_innovation_idx"] = current_idx
    current_text = innovations[current_idx] if current_idx < len(innovations) else ""
    
    return (
        pr_session_state,
        current_text,
        f"åˆ›æ–°ç‚¹ {current_idx + 1}/{len(innovations)}"
    )


def update_keyword_display(pr_session_state, direction):
    """æ›´æ–° Agent2 å…³é”®è¯å±•ç¤º"""
    if not pr_session_state:
        return pr_session_state, gr.update(), gr.update()
    
    current_idx = pr_session_state.get("current_keyword_idx", 0)
    keywords = pr_session_state.get("agent2_data", {}).get("keywords", [])
    
    if not keywords:
        return pr_session_state, gr.update(), gr.update()
    
    if direction == "next":
        current_idx = min(current_idx + 1, len(keywords) - 1)
    elif direction == "prev":
        current_idx = max(current_idx - 1, 0)
    
    pr_session_state["current_keyword_idx"] = current_idx
    current_text = keywords[current_idx] if current_idx < len(keywords) else ""
    
    return (
        pr_session_state,
        current_text,
        f"å…³é”®è¯ {current_idx + 1}/{len(keywords)}"
    )


def update_agent3_display(pr_session_state, direction):
    """æ›´æ–° Agent3 å±•ç¤º"""
    if not pr_session_state:
        return pr_session_state, gr.update(), gr.update()
    
    current_idx = pr_session_state.get("current_agent3_idx", 0)
    agent3_data = pr_session_state.get("agent3_data", [])
    
    if not agent3_data:
        return pr_session_state, gr.update(), gr.update()
    
    if direction == "next":
        current_idx = min(current_idx + 1, len(agent3_data) - 1)
    elif direction == "prev":
        current_idx = max(current_idx - 1, 0)
    
    pr_session_state["current_agent3_idx"] = current_idx
    current_text = agent3_data[current_idx] if current_idx < len(agent3_data) else ""
    
    return (
        pr_session_state,
        current_text,
        f"åˆ›æ–°ç‚¹åˆ†æ {current_idx + 1}/{len(agent3_data)}"
    )


def update_agent4_display(pr_session_state, direction):
    """æ›´æ–° Agent4 å±•ç¤º"""
    if not pr_session_state:
        return pr_session_state, gr.update(), gr.update()
    
    current_idx = pr_session_state.get("current_agent4_idx", 0)
    agent4_data = pr_session_state.get("agent4_data", [])
    
    if not agent4_data:
        return pr_session_state, gr.update(), gr.update()
    
    if direction == "next":
        current_idx = min(current_idx + 1, len(agent4_data) - 1)
    elif direction == "prev":
        current_idx = max(current_idx - 1, 0)
    
    pr_session_state["current_agent4_idx"] = current_idx
    current_text = agent4_data[current_idx] if current_idx < len(agent4_data) else ""
    
    return (
        pr_session_state,
        current_text,
        f"åº”ç”¨ä»·å€¼åˆ†æ {current_idx + 1}/{len(agent4_data)}"
    )



# åº”ç”¨ CSS
APP_CSS = """
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap');
    
    /* å…¨å±€å­—ä½“ï¼šè‹±è¯­ä½¿ç”¨ Georgiaï¼Œä¸­æ–‡ä½¿ç”¨ Noto Sans SC */
    * {
        font-family: Georgia, 'Noto Sans SC', 'PingFang SC', 'Hiragino Sans GB', sans-serif !important;
    }
    .prose, .prose * {
        font-family: Georgia, 'Noto Sans SC', 'PingFang SC', 'Hiragino Sans GB', sans-serif !important;
    }
    /* ä»£ç å—ä¿æŒç­‰å®½å­—ä½“ */
    code, pre, .code, pre *, code * {
        font-family: 'Consolas', 'Monaco', 'Courier New', monospace !important;
    }
    .strategy-preview {
        background: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 12px;
        padding: 24px;
        line-height: 1.8;
        max-height: 600px;
        overflow-y: auto;
    }
    .strategy-preview h3 {
        color: #1e40af;
        border-bottom: 2px solid #3b82f6;
        padding-bottom: 8px;
        margin-top: 20px;
    }
    .strategy-preview h4 {
        color: #7c3aed;
        margin-top: 16px;
    }
    .strategy-preview strong {
        color: #1e293b;
        border-radius: 4px; /* å¯é€‰ï¼šå¢åŠ è½»å¾®é«˜äº®å…³è” */
    }
    .strategy-preview table {
        width: 100%;
        border-collapse: collapse;
        margin: 12px 0;
    }
    .strategy-preview th, .strategy-preview td {
        border: 1px solid #e2e8f0;
        padding: 8px 12px;
        text-align: left;
    }
    .strategy-preview th {
        background: #f1f5f9;
    }
    .strategy-edit textarea {
        font-family: 'Consolas', 'Monaco', monospace !important;
        font-size: 13px !important;
        line-height: 1.5 !important;
        background: #1e293b !important;
        color: #e2e8f0 !important;
        border-radius: 8px !important;
    }
    .question-box {
        background: linear-gradient(135deg, #fef3c7, #fef9c3);
        border-left: 4px solid #f59e0b;
        border-radius: 8px;
        padding: 16px;
    }
    .feedback-box textarea {
        border: 2px solid #4CAF50;
    }
    #log-display {
        background: #f8fafc;
        color: #334155;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px;
        font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
        font-size: 12px;
        line-height: 1.6;
        max-height: 300px;
        overflow-y: auto;
    }
    /* ä¸‹è½½æç¤ºåŠ¨ç”» */
    @keyframes pulse-glow {
        0%, 100% {
            opacity: 1;
            transform: scale(1);
        }
        50% {
            opacity: 0.7;
            transform: scale(1.02);
        }
    }
    @keyframes arrow-bounce {
        0%, 100% { transform: translateX(0); }
        50% { transform: translateX(5px); }
    }
    .download-tip {
        background: linear-gradient(135deg, #fef3c7, #fde68a);
        border: 2px solid #f59e0b;
        border-radius: 12px;
        padding: 12px 16px;
        margin-top: 12px;
        animation: pulse-glow 2s ease-in-out infinite;
    }
    .download-tip em {
        font-style: normal;
        display: flex;
        align-items: center;
        gap: 8px;
    }
    /* é‡è¦è­¦ç¤ºä¿¡æ¯ - å•å±‚æ ·å¼ */
    .important-warning {
        background: linear-gradient(135deg, #fef2cd, #fff3cd) !important;
        border: 2px solid #ff9800 !important;
        border-left: 6px solid #ff5722 !important;
        border-radius: 8px !important;
        padding: 16px 20px !important;
        margin: 16px 0 !important;
        box-shadow: 0 4px 12px rgba(255, 152, 0, 0.25) !important;
    }
    .important-warning * {
        background: transparent !important;
        border: none !important;
        box-shadow: none !important;
        padding: 0 !important;
        margin: 0 !important;
    }
    .important-warning p {
        margin: 4px 0 !important;
        color: #5d4037 !important;
        font-weight: 500 !important;
    }
    /* æ˜äº®çš„ä¸‹è½½æŒ‰é’® */
    #download-strategy-btn, #download-rebuttal-btn {
        background: linear-gradient(135deg, #22c55e, #16a34a) !important;
        border: none !important;
        color: white !important;
        font-weight: bold !important;
        font-size: 16px !important;
        padding: 16px 24px !important;
        box-shadow: 0 4px 15px rgba(34, 197, 94, 0.4) !important;
        transition: all 0.3s ease !important;
    }
    #download-strategy-btn:hover, #download-rebuttal-btn:hover {
        background: linear-gradient(135deg, #16a34a, #15803d) !important;
        box-shadow: 0 6px 20px rgba(34, 197, 94, 0.6) !important;
        transform: translateY(-2px) !important;
    }
"""

with gr.Blocks(title="AI è®ºæ–‡åŠ©æ‰‹") as demo:
    
    session_state = gr.State(None)
    pr_session_state = gr.State(None)
    
    gr.Markdown(
        """
        # AI è®ºæ–‡åŠ©æ‰‹
        
        é¢å‘å­¦æœ¯è®ºæ–‡çš„åˆ†æä¸å¤„ç†æµç¨‹ã€‚
        """
    )
    
    with gr.Tabs() as main_tabs:
        with gr.TabItem("è®ºæ–‡é˜…è¯»"):
            gr.Markdown(
                """
                **è®ºæ–‡é˜…è¯»æµç¨‹ï¼š**
                - **ä¸Šä¼ ** - ä¸Šä¼ è®ºæ–‡ PDF ä¸ç ”ç©¶é¢†åŸŸæè¿°ï¼ˆ.md æ–‡ä»¶ï¼‰
                - **åˆ†æ** - ç³»ç»Ÿé€šè¿‡ 5 ä¸ªæ™ºèƒ½ä½“åˆ†æè®ºæ–‡ï¼š
                  1. æå–æ ¸å¿ƒåŠ¨æœºä¸åˆ›æ–°ç‚¹
                  2. ç»†åŒ–å¹¶éªŒè¯åˆ†æç»“æœ
                  3. é€æ¡æ·±å…¥åˆ†æåˆ›æ–°ç‚¹
                  4. åœ¨ç ”ç©¶é¢†åŸŸå†…åˆ†æåº”ç”¨ä»·å€¼
                  5. è¯„ä¼°å†™ä½œè´¨é‡
                - **æŸ¥çœ‹** - ä½¿ç”¨å¯¼èˆªæ§ä»¶æµè§ˆåˆ†æç»“æœ
                """
            )
            
            with gr.Column(visible=True) as pr_upload_col:
                gr.Markdown("## ğŸ“¤ é…ç½®å¹¶ä¸Šä¼ æ–‡ä»¶")
                
                with gr.Group():
                    gr.Markdown("### ğŸ”‘ API é…ç½®")
                    
                    pr_provider_choice = gr.Dropdown(
                        label="LLM ä¾›åº”å•†",
                        choices=list(PROVIDER_CONFIGS.keys()),
                        value="OpenRouter",
                        info="è¯·é€‰æ‹©ä½ çš„ LLM ä¾›åº”å•†",
                    )
                    
                    pr_env_api_key = get_api_key_for_provider("OpenRouter")
                    pr_api_key_input = gr.Textbox(
                        label=PROVIDER_CONFIGS["OpenRouter"]["label"],
                        placeholder=f"è¯·è¾“å…¥ API å¯†é’¥ï¼ˆ{PROVIDER_CONFIGS['OpenRouter']['placeholder']}ï¼‰",
                        value=pr_env_api_key,
                        type="password",
                        info="API å¯†é’¥ä¸ä¼šè¢«å­˜å‚¨ï¼Œä»…ç”¨äºæœ¬æ¬¡ä¼šè¯ã€‚" + ("ï¼ˆå·²ä» .env è½½å…¥ï¼‰" if pr_env_api_key else "")
                    )
                    
                    def pr_on_provider_change(provider):
                        config = PROVIDER_CONFIGS.get(provider, PROVIDER_CONFIGS["OpenRouter"])
                        env_key = get_api_key_for_provider(provider)
                        model_choices = MODEL_CHOICES_BY_PROVIDER.get(provider, MODEL_CHOICES_BY_PROVIDER["OpenRouter"])
                        default_model = get_default_model_for_provider(provider)
                        
                        return (
                            gr.update(
                                label=config["label"],
                                placeholder=f"è¯·è¾“å…¥ API å¯†é’¥ï¼ˆ{config['placeholder']}ï¼‰",
                                value=env_key,
                                info="API å¯†é’¥ä¸ä¼šè¢«å­˜å‚¨ï¼Œä»…ç”¨äºæœ¬æ¬¡ä¼šè¯ã€‚" + ("ï¼ˆå·²ä» .env è½½å…¥ï¼‰" if env_key else "")
                            ),
                            gr.update(
                                choices=list(model_choices.keys()),
                                value=default_model,
                            ),
                        )
                
                gr.Markdown("---")
                
                with gr.Group():
                    gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
                    with gr.Row():
                        pr_model_choice = gr.Dropdown(
                            label="é€‰æ‹©æ¨¡å‹",
                            choices=list(MODEL_CHOICES_BY_PROVIDER["OpenRouter"].keys()),
                            value="Gemini 3 Flash",
                            info="é€‰æ‹©è¦ä½¿ç”¨çš„ LLM æ¨¡å‹",
                            scale=2,
                        )
                        pr_custom_model_input = gr.Textbox(
                            label="è‡ªå®šä¹‰æ¨¡å‹åç§°",
                            placeholder="è¯·è¾“å…¥æ¨¡å‹åç§°",
                            visible=False,
                            scale=3,
                        )
                    
                    def pr_toggle_custom_model(choice):
                        return gr.update(visible=(choice == "å…¶ä»–æ¨¡å‹"))
                    
                    pr_model_choice.change(
                        fn=pr_toggle_custom_model,
                        inputs=[pr_model_choice],
                        outputs=[pr_custom_model_input],
                    )
                    
                    pr_provider_choice.change(
                        fn=pr_on_provider_change,
                        inputs=[pr_provider_choice],
                        outputs=[pr_api_key_input, pr_model_choice],
                    )
                
                gr.Markdown("---")
                
                gr.Markdown("### ğŸ“„ ä¸Šä¼ æ–‡ä»¶")
                with gr.Row():
                    pr_pdf_input = gr.File(
                        label="ğŸ“„ è®ºæ–‡ PDF",
                        file_types=[".pdf"],
                        file_count="single",
                    )
                    pr_research_field_input = gr.File(
                        label="ğŸ“ ç ”ç©¶é¢†åŸŸæè¿°ï¼ˆ.mdï¼‰",
                        file_types=[".md"],
                        file_count="single",
                    )
                
                pr_upload_status = gr.Markdown("")
                
                pr_start_btn = gr.Button(
                    "ğŸš€ æäº¤å¹¶å¼€å§‹åˆ†æ",
                    variant="primary",
                    size="lg",
                )
            
            with gr.Column(visible=False) as pr_loading_col:
                gr.Markdown("## â³ æ­£åœ¨åˆ†æ...")
                pr_loading_status = gr.Markdown("åˆå§‹åŒ–ä¸­...")
                
                gr.Markdown(
                    """
                    > ğŸ“Š **åˆ†ææµç¨‹ï¼š**
                    > 1. å°† PDF è½¬æ¢ä¸º Markdown
                    > 2. Agent1ï¼šæå–æ ¸å¿ƒåŠ¨æœºä¸åˆ›æ–°ç‚¹
                    > 3. Agent2ï¼šç»†åŒ–å¹¶éªŒè¯åˆ†æ
                    > 4. Agent3ï¼šé€æ¡æ·±å…¥åˆ†æåˆ›æ–°ç‚¹ï¼ˆå¹¶è¡Œï¼‰
                    > 5. Agent4ï¼šåˆ†æåœ¨ç ”ç©¶é¢†åŸŸçš„åº”ç”¨ä»·å€¼ï¼ˆå¹¶è¡Œï¼‰
                    > 6. Agent5ï¼šè¯„ä¼°å†™ä½œè´¨é‡
                    > 7. è¾“å‡ºç»“æœä¾›ä½ æŸ¥çœ‹
                    
                    è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...
                    """
                )
                
                gr.Markdown("### ğŸ“‹ å®æ—¶æ—¥å¿—")
                pr_log_display = gr.Textbox(
                    value="ç­‰å¾…å¼€å§‹...",
                    label="",
                    lines=10,
                    max_lines=15,
                    interactive=False,
                    elem_id="log-display",
                )

                pr_log_timer = gr.Timer(value=1.5, active=False)
            
            with gr.Column(visible=False) as pr_result_col:
                gr.Markdown("## ğŸ“Š åˆ†æç»“æœ")
                
                gr.Markdown("### Agent1ï¼šæ ¸å¿ƒæ‘˜è¦")
                pr_agent1_output = gr.Textbox(
                    label="Agent1 è¾“å‡ºï¼ˆJSONï¼‰",
                    lines=8,
                    max_lines=15,
                    interactive=False,
                )
                
                gr.Markdown("---")
                gr.Markdown("### Agent2ï¼šå®Œæ•´æ‘˜è¦ä¸åˆ›æ–°ç‚¹")
                pr_agent2_summary = gr.Textbox(
                    label="å®Œæ•´æ‘˜è¦",
                    lines=6,
                    max_lines=10,
                    interactive=False,
                )
                
                with gr.Row():
                    pr_innovation_prev_btn = gr.Button("â—€ ä¸Šä¸€æ¡", size="sm")
                    pr_innovation_index = gr.Markdown("åˆ›æ–°ç‚¹ 1/1")
                    pr_innovation_next_btn = gr.Button("ä¸‹ä¸€æ¡ â–¶", size="sm")
                pr_agent2_innovation = gr.Textbox(
                    label="å½“å‰åˆ›æ–°ç‚¹",
                    lines=4,
                    max_lines=8,
                    interactive=False,
                )
                
                with gr.Row():
                    pr_keyword_prev_btn = gr.Button("â—€ ä¸Šä¸€æ¡", size="sm")
                    pr_keyword_index = gr.Markdown("å…³é”®è¯ 1/1")
                    pr_keyword_next_btn = gr.Button("ä¸‹ä¸€æ¡ â–¶", size="sm")
                pr_agent2_keyword = gr.Textbox(
                    label="å½“å‰å…³é”®è¯",
                    lines=2,
                    max_lines=4,
                    interactive=False,
                )
                
                gr.Markdown("---")
                gr.Markdown("### Agent3ï¼šåˆ›æ–°ç‚¹åˆ†æ")
                with gr.Row():
                    pr_agent3_prev_btn = gr.Button("â—€ ä¸Šä¸€æ¡", size="sm")
                    pr_agent3_index = gr.Markdown("åˆ›æ–°ç‚¹åˆ†æ 1/1")
                    pr_agent3_next_btn = gr.Button("ä¸‹ä¸€æ¡ â–¶", size="sm")
                pr_agent3_output = gr.Textbox(
                    label="å½“å‰åˆ›æ–°ç‚¹åˆ†æ",
                    lines=12,
                    max_lines=20,
                    interactive=False,
                )
                
                gr.Markdown("---")
                gr.Markdown("### Agent4ï¼šåº”ç”¨ä»·å€¼åˆ†æ")
                with gr.Row():
                    pr_agent4_prev_btn = gr.Button("â—€ ä¸Šä¸€æ¡", size="sm")
                    pr_agent4_index = gr.Markdown("åº”ç”¨ä»·å€¼åˆ†æ 1/1")
                    pr_agent4_next_btn = gr.Button("ä¸‹ä¸€æ¡ â–¶", size="sm")
                pr_agent4_output = gr.Textbox(
                    label="å½“å‰åº”ç”¨ä»·å€¼åˆ†æ",
                    lines=12,
                    max_lines=20,
                    interactive=False,
                )
                
                gr.Markdown("---")
                gr.Markdown("### Agent5ï¼šå†™ä½œè´¨é‡è¯„ä¼°")
                pr_agent5_output = gr.Textbox(
                    label="Agent5 è¾“å‡ºï¼ˆJSONï¼‰",
                    lines=8,
                    max_lines=15,
                    interactive=False,
                )
            
            pr_start_btn.click(
                fn=start_paper_reading,
                inputs=[pr_pdf_input, pr_research_field_input, pr_provider_choice, pr_api_key_input, pr_model_choice, pr_custom_model_input],
                outputs=[
                    pr_upload_col, pr_loading_col, pr_result_col,
                    pr_session_state, pr_upload_status, pr_log_timer,
                ],
            ).then(
                fn=run_paper_reading_workflow,
                inputs=[pr_session_state],
                outputs=[
                    pr_upload_col, pr_loading_col, pr_result_col,
                    pr_session_state, pr_loading_status,
                    pr_agent1_output,
                    pr_agent2_summary,
                    pr_agent2_innovation,
                    pr_innovation_index,
                    pr_agent2_keyword,
                    pr_keyword_index,
                    pr_agent3_output,
                    pr_agent3_index,
                    pr_agent4_output,
                    pr_agent4_index,
                    pr_agent5_output,
                    pr_log_timer,
                ],
            )
            
            pr_log_timer.tick(
                fn=poll_pr_logs,
                inputs=[pr_session_state],
                outputs=[pr_log_display, pr_session_state],
            )
            
            pr_innovation_prev_btn.click(
                fn=lambda state: update_innovation_display(state, "prev"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent2_innovation, pr_innovation_index],
            )
            
            pr_innovation_next_btn.click(
                fn=lambda state: update_innovation_display(state, "next"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent2_innovation, pr_innovation_index],
            )
            
            pr_keyword_prev_btn.click(
                fn=lambda state: update_keyword_display(state, "prev"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent2_keyword, pr_keyword_index],
            )
            
            pr_keyword_next_btn.click(
                fn=lambda state: update_keyword_display(state, "next"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent2_keyword, pr_keyword_index],
            )
            
            pr_agent3_prev_btn.click(
                fn=lambda state: update_agent3_display(state, "prev"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent3_output, pr_agent3_index],
            )
            
            pr_agent3_next_btn.click(
                fn=lambda state: update_agent3_display(state, "next"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent3_output, pr_agent3_index],
            )
            
            pr_agent4_prev_btn.click(
                fn=lambda state: update_agent4_display(state, "prev"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent4_output, pr_agent4_index],
            )
            
            pr_agent4_next_btn.click(
                fn=lambda state: update_agent4_display(state, "next"),
                inputs=[pr_session_state],
                outputs=[pr_session_state, pr_agent4_output, pr_agent4_index],
            )

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="AI è®ºæ–‡åŠ©æ‰‹")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å¼€é“¾æ¥")
    parser.add_argument("--device", type=str, default="cpu", choices=["cpu", "cuda"], 
                        help="docling PDF å¤„ç†è®¾å¤‡ï¼ˆcpu æˆ– cudaï¼‰")
    
    args = parser.parse_args()
    
    device_used = os.environ.get("DOCLING_DEVICE", "cpu")
    
    print(f"\nğŸš€ å¯åŠ¨ AI è®ºæ–‡åŠ©æ‰‹")
    print(f"   åœ°å€: http://localhost:{args.port}")
    print(f"   è®¾å¤‡: {device_used.upper()}")
    print(f"   å…±äº«: {'æ˜¯' if args.share else 'å¦'}\n")
    
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
        theme=gr.themes.Soft(),  # Moved here for Gradio 6.0
        css=APP_CSS,             # Moved here for Gradio 6.0
    )
